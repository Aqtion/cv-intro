{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "BlueRov video capture class\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import gi\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gi.require_version('Gst', '1.0')\n",
    "from gi.repository import Gst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Video():\n",
    "    \"\"\"BlueRov video capture class constructor\n",
    "\n",
    "    Attributes:\n",
    "        port (int): Video UDP port\n",
    "        video_codec (string): Source h264 parser\n",
    "        video_decode (string): Transform YUV (12bits) to BGR (24bits)\n",
    "        video_pipe (object): GStreamer top-level pipeline\n",
    "        video_sink (object): Gstreamer sink element\n",
    "        video_sink_conf (string): Sink configuration\n",
    "        video_source (string): Udp source ip and port\n",
    "        latest_frame (np.ndarray): Latest retrieved video frame\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, port=5600):\n",
    "        \"\"\"Summary\n",
    "\n",
    "        Args:\n",
    "            port (int, optional): UDP port\n",
    "        \"\"\"\n",
    "\n",
    "        Gst.init(None)\n",
    "\n",
    "        self.port = port\n",
    "        self.latest_frame = self._new_frame = None\n",
    "\n",
    "        # [Software component diagram](https://www.ardusub.com/software/components.html)\n",
    "        # UDP video stream (:5600)\n",
    "        self.video_source = 'udpsrc port={}'.format(self.port)\n",
    "        # [Rasp raw image](http://picamera.readthedocs.io/en/release-0.7/recipes2.html#raw-image-capture-yuv-format)\n",
    "        # Cam -> CSI-2 -> H264 Raw (YUV 4-4-4 (12bits) I420)\n",
    "        self.video_codec = '! application/x-rtp, payload=96 ! rtph264depay ! h264parse ! avdec_h264'\n",
    "        # Python don't have nibble, convert YUV nibbles (4-4-4) to OpenCV standard BGR bytes (8-8-8)\n",
    "        self.video_decode = \\\n",
    "            '! decodebin ! videoconvert ! video/x-raw,format=(string)BGR ! videoconvert'\n",
    "        # Create a sink to get data\n",
    "        self.video_sink_conf = \\\n",
    "            '! appsink emit-signals=true sync=false max-buffers=2 drop=true'\n",
    "\n",
    "        self.video_pipe = None\n",
    "        self.video_sink = None\n",
    "\n",
    "        self.run()\n",
    "\n",
    "    def start_gst(self, config=None):\n",
    "        \"\"\" Start gstreamer pipeline and sink\n",
    "        Pipeline description list e.g:\n",
    "            [\n",
    "                'videotestsrc ! decodebin', \\\n",
    "                '! videoconvert ! video/x-raw,format=(string)BGR ! videoconvert',\n",
    "                '! appsink'\n",
    "            ]\n",
    "\n",
    "        Args:\n",
    "            config (list, optional): Gstreamer pileline description list\n",
    "        \"\"\"\n",
    "\n",
    "        if not config:\n",
    "            config = \\\n",
    "                [\n",
    "                    'videotestsrc ! decodebin',\n",
    "                    '! videoconvert ! video/x-raw,format=(string)BGR ! videoconvert',\n",
    "                    '! appsink'\n",
    "                ]\n",
    "\n",
    "        command = ' '.join(config)\n",
    "        self.video_pipe = Gst.parse_launch(command)\n",
    "        self.video_pipe.set_state(Gst.State.PLAYING)\n",
    "        self.video_sink = self.video_pipe.get_by_name('appsink0')\n",
    "\n",
    "    @staticmethod\n",
    "    def gst_to_opencv(sample):\n",
    "        \"\"\"Transform byte array into np array\n",
    "\n",
    "        Args:\n",
    "            sample (TYPE): Description\n",
    "\n",
    "        Returns:\n",
    "            TYPE: Description\n",
    "        \"\"\"\n",
    "        buf = sample.get_buffer()\n",
    "        caps_structure = sample.get_caps().get_structure(0)\n",
    "        array = np.ndarray(\n",
    "            (\n",
    "                caps_structure.get_value('height'),\n",
    "                caps_structure.get_value('width'),\n",
    "                3\n",
    "            ),\n",
    "            buffer=buf.extract_dup(0, buf.get_size()), dtype=np.uint8)\n",
    "        return array\n",
    "\n",
    "    def frame(self):\n",
    "        \"\"\" Get Frame\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: latest retrieved image frame\n",
    "        \"\"\"\n",
    "        if self.frame_available:\n",
    "            self.latest_frame = self._new_frame\n",
    "            # reset to indicate latest frame has been 'consumed'\n",
    "            self._new_frame = None\n",
    "        return self.latest_frame\n",
    "\n",
    "    def frame_available(self):\n",
    "        \"\"\"Check if a new frame is available\n",
    "\n",
    "        Returns:\n",
    "            bool: true if a new frame is available\n",
    "        \"\"\"\n",
    "        return self._new_frame is not None\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\" Get frame to update _new_frame\n",
    "        \"\"\"\n",
    "\n",
    "        self.start_gst(\n",
    "            [\n",
    "                self.video_source,\n",
    "                self.video_codec,\n",
    "                self.video_decode,\n",
    "                self.video_sink_conf\n",
    "            ])\n",
    "\n",
    "        self.video_sink.connect('new-sample', self.callback)\n",
    "\n",
    "    def callback(self, sink):\n",
    "        sample = sink.emit('pull-sample')\n",
    "        self._new_frame = self.gst_to_opencv(sample)\n",
    "\n",
    "        return Gst.FlowReturn.OK\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "video = Video()\n",
    "\n",
    "print('Initialising stream...')\n",
    "waited = 0\n",
    "while not video.frame_available():\n",
    "    waited += 1\n",
    "    print('\\r  Frame not available (x{})'.format(waited), end='')\n",
    "    cv2.waitKey(30)\n",
    "print('\\nSuccess!\\nStarting streaming - press \"q\" to quit.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Wait for the next frame to become available\n",
    "if video.frame_available():\n",
    "    # Only retrieve and display a frame if it's new\n",
    "    frame = video.frame()\n",
    "    #cv2.imshow('frame', frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bluecv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "04c0fcea70dda6048aeae827e76ba8fc20c8a61759a06da91d2e948a06278481"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
